nohup: ignoring input
/home/michaelbezick/.conda/envs/AIL_w_DA/lib/python3.9/site-packages/torchvision/transforms/_functional_pil.py:242: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.
  interpolation: int = Image.BILINEAR,
/home/michaelbezick/.conda/envs/AIL_w_DA/lib/python3.9/site-packages/torchvision/transforms/_functional_pil.py:288: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.
  interpolation: int = Image.NEAREST,
/home/michaelbezick/.conda/envs/AIL_w_DA/lib/python3.9/site-packages/torchvision/transforms/_functional_pil.py:304: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.
  interpolation: int = Image.NEAREST,
/home/michaelbezick/.conda/envs/AIL_w_DA/lib/python3.9/site-packages/torchvision/transforms/_functional_pil.py:321: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.
  interpolation: int = Image.BICUBIC,
/home/michaelbezick/.conda/envs/AIL_w_DA/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/michaelbezick/.conda/envs/AIL_w_DA/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Raft_Small_Weights.C_T_V2`. You can also use `weights=Raft_Small_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/home/michaelbezick/.conda/envs/AIL_w_DA/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
workspace: /home/michaelbezick/Repos/C-LAIfO/experiments/exp_walker_walk_walker_walk_difficulty=easy_delta_source=0.2_delta_target=-0.25/lail_cl_multiset_apply_aug=CL-Q_aug_type=brightness_CL_data_type=agent_2025.01.22/0930_CL_data_type=agent,agent=lail_cl_multiset,apply_aug=CL-Q,aug_type=brightness,delta_source=0.2,delta_target=-0.25,difficulty=easy,task_agent=walker_walk,task_expert=walker_walk
loading expert target: /home/michaelbezick/Repos/C-LAIfO/expert_policies/snapshot_walker_walk_frame_skip_1.pt
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
Average expert reward: 947.6108594765435, Total number of samples: 100000
Average random expert reward: 31.331272930429975, Total number of samples: 1000
1
| [32meval[0m  | F: 0 | S: 0 | E: 0 | L: 1000 | R: 37.5902 | T: 0:08:34
Error executing job with overrides: ['task_agent=walker_walk', 'task_expert=walker_walk', 'agent=lail_cl_multiset', 'difficulty=easy', 'delta_source=0.2', 'delta_target=-0.25', 'apply_aug=CL-Q', 'aug_type=brightness', 'CL_data_type=agent']
Traceback (most recent call last):
  File "/home/michaelbezick/Repos/C-LAIfO/train_LAIL_MI.py", line 372, in main
    workspace.train()
  File "/home/michaelbezick/Repos/C-LAIfO/train_LAIL_MI.py", line 288, in train
    metrics = self.agent.update(self.replay_buffer,
  File "/home/michaelbezick/Repos/C-LAIfO/agents/multi_dataset/lail_cl.py", line 878, in update
    metrics.update(self.update_CL(obs,
  File "/home/michaelbezick/Repos/C-LAIfO/agents/multi_dataset/lail_cl.py", line 826, in update_CL
    z_anchor = self.encoder(anchors)
  File "/home/michaelbezick/.conda/envs/AIL_w_DA/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/michaelbezick/.conda/envs/AIL_w_DA/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/michaelbezick/Repos/C-LAIfO/agents/multi_dataset/lail_cl.py", line 301, in forward
    h = self.attention(h)
  File "/home/michaelbezick/.conda/envs/AIL_w_DA/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/michaelbezick/.conda/envs/AIL_w_DA/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/michaelbezick/Repos/C-LAIfO/agents/multi_dataset/lail_cl.py", line 73, in forward
    w_ = torch.bmm(q, k)  # b,hw,hw    w[b,i,j]=sum_c q[b,i,c]k[b,c,j]
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 28.19 GiB. GPU 0 has a total capacty of 23.70 GiB of which 3.10 GiB is free. Process 33242 has 16.67 GiB memory in use. Including non-PyTorch memory, this process has 3.91 GiB memory in use. Of the allocated memory 1.89 GiB is allocated by PyTorch, and 373.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
